{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:23:21.802797Z",
     "start_time": "2019-11-20T05:23:10.686163Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:23:21.819788Z",
     "start_time": "2019-11-20T05:23:21.808795Z"
    }
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:24:17.725780Z",
     "start_time": "2019-11-20T05:23:21.826784Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_hdf('../data//tokenized_10thousand.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:24:18.234488Z",
     "start_time": "2019-11-20T05:24:18.089570Z"
    }
   },
   "outputs": [],
   "source": [
    "# json으로 저장한 단어 사전 불러오기\n",
    "import json\n",
    "\n",
    "with open('./id_dict/input_id.json', 'r') as fp:\n",
    "    input_id = json.load(fp)\n",
    "\n",
    "with open('./id_dict/target_id.json', 'r') as fp:\n",
    "    target_id = json.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:25:22.977417Z",
     "start_time": "2019-11-20T05:24:18.261471Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터셋을 아이디값으로 변환(vectorize)\n",
    "original = df.original.apply(lambda y :np.array(list(map(lambda x:input_id[x], y)))).to_numpy()\n",
    "# 한글의 경우 20000개 안에 없는 단어가 있을 수 있다.\n",
    "# OOV 아이디인 1로 바꿔줘야 한다.\n",
    "translation = df.translation.apply(lambda y :np.array(list(map(lambda x:target_id.setdefault(x, 1), y)))).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:26:48.450477Z",
     "start_time": "2019-11-20T05:25:23.034384Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:26:54.110238Z",
     "start_time": "2019-11-20T05:26:48.480461Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_input_data = pad_sequences(original, maxlen=200, padding='post', truncating='post')\n",
    "decoder_target_data = pad_sequences(translation, maxlen=200, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:26:54.201185Z",
     "start_time": "2019-11-20T05:26:54.117234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11, 516, 202, ..., 713, 604, 426],\n",
       "       [ 11,  14, 117, ..., 178,  24,   3],\n",
       "       [ 11, 345, 613, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [ 11, 391,  44, ...,   0,   0,   0],\n",
       "       [ 11, 510,  43, ...,   0,   0,   0],\n",
       "       [ 11, 413, 590, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:28:31.355040Z",
     "start_time": "2019-11-20T05:26:54.210180Z"
    }
   },
   "outputs": [],
   "source": [
    "# decoder input data는 <start> character (== 2)로 시작해야 하며 1 time 씩 밀어내야 한다.\n",
    "tmp = []\n",
    "for t in translation:\n",
    "    a = [2]\n",
    "    a.extend(list(t))\n",
    "    tmp.append(a)\n",
    "tmp = np.array(tmp)\n",
    "\n",
    "decoder_input_data = pad_sequences(tmp, maxlen=200, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:28:31.435996Z",
     "start_time": "2019-11-20T05:28:31.380028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2,  913,   22, ...,   88,   26,   58],\n",
       "       [   2,   65,    7, ...,   15,    5, 1647],\n",
       "       [   2,  421,   22, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   2,  717,    1, ...,    0,    0,    0],\n",
       "       [   2, 2362,  416, ...,    0,    0,    0],\n",
       "       [   2,  139,    4, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:28:31.462980Z",
     "start_time": "2019-11-20T05:28:31.445990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((99996, 200), (99996, 200), (99996, 200))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data.shape, decoder_target_data.shape, decoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:28:31.499959Z",
     "start_time": "2019-11-20T05:28:31.470976Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1  # Batch size for training.\n",
    "epochs = 1  # Number of epochs to train for.\n",
    "latent_dim = 256  # 인코더 차원\n",
    "num_encoder_tokens = 7049 # unique한 한자 캐릭터의 수\n",
    "num_decoder_tokens = 10003 # unique한 한글 토큰의 수\n",
    "embedding_dim = 256 # 워드 임베딩 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:28:31.593906Z",
     "start_time": "2019-11-20T05:28:31.511951Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Softmax\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:28:40.384872Z",
     "start_time": "2019-11-20T05:28:31.605897Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_input = Input(shape=(None,))\n",
    "encoder_embedding = Embedding(num_encoder_tokens, embedding_dim)(encoder_input)\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_embedding)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_input = Input(shape=(None,))\n",
    "decoder_embedding = Embedding(num_decoder_tokens, embedding_dim)(decoder_input)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_input, decoder_input], decoder_outputs)\n",
    "\n",
    "# Run training\n",
    "# model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "# model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           validation_split=0.2)\n",
    "# # Save model\n",
    "# model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:28:40.402860Z",
     "start_time": "2019-11-20T05:28:40.393867Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:32:18.466020Z",
     "start_time": "2019-11-20T05:28:40.415854Z"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model('./s2s.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:37:02.981065Z",
     "start_time": "2019-11-20T05:37:02.969072Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:37:23.480327Z",
     "start_time": "2019-11-20T05:37:21.814282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcsAAAHBCAYAAAAGmZAhAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO3df3Ac9X3/8ddalrECRg5gGwyIHwFjIEGBtGCLHy7GJIzNyRAQsWRjQ6c2p9jOL0wLRPpCBhraRiqkcUaulCaTOPoBSsDoCkw6SElFbAkaUrkpJXLIjxM2RSKBO0OcGln+fP9wdnM63WnvpNPt3er5mLmxb+9z+3nf7u29tLufvbOMMUYAACCZLTO8rgAAgFxHWAIA4IKwBADABWEJAICLmV50GgqFtHPnTi+6BjLmvPPO05e//GWvywCQBZ7sWba1tam9vd2LroGMaG9v1yOPPOJ1GQCyxJM9S0mqqqpSc3OzV90Dk9LS0qK1a9d6XQaALOGcJQAALghLAABcEJYAALggLAEAcEFYAgDggrAEAMAFYQkAgAvCEgAAF4QlAAAuCEsAAFwQlgAAuCAsAQBwQVgCAOCCsAQAwEXehGVtba1qa2u9LgMAMA3lTVh6LRqNyrKsCT+3t7dXTU1NKi8vn3AbN5ZlJbx5IX555VJtAJAuz378OV0PPfSQp/13d3dP+Ll1dXWSpIcffnhSbdwYYxSNRjV37lxJUiQSUXFx8YTnNxnxy8sYo6GhIS1YsECSt7UBQLosY4zJdqf2L8w3Nzdnu+sJiUajuv322xUKhTSZxWXvSY03j1TaZKKfqTTe8vK6tkxpaWnR2rVr8/51AEjJlrw4DDs0NKS2tjbn8GT8/VAoJMuyVF5eroGBAadNKBRy2jQ1NcmyLFVXV2vfvn3OvBMdEoyfVldXp1AoNOoxL0z0vG0+Lq9oNOrUYFmWamtrNTQ0pPr6+lH91dfXO8+JfSz2ddnTy8vL1dXVNeb1RqNRVVdXc04cQHLGA1VVVaaqqirl9oFAwEgydrmx93t6eowxxoTDYSPJBINBY4xxHo9tE4lETDAYNJJMf3+/McaYwcHBUfOOnVfstPj7E5HKPMZrU1NTY2pqatLuJ5eWV6rL0e53cHBwTK09PT2j7scKBAJmcHDQqTUQCJjW1lZjjDGdnZ1Gkunr6xuzTPr6+hLOL5nm5uZJvx8A5I3NeRGWxoz9kE30oZtKm76+PiPJ1NXVTXpe6ZpsWE6mn1xZXqm+vpqamlHhFf+8uro6I8mEw+FRtdrBaIwxra2tCeu0/+Cw5xmJRFzriUdYAtPK5rw4DJtJpaWlkqRt27Z5XEl+8Gp5PfTQQ2poaNDAwMCoQ622FStWSJJ+8IMfONOef/55lZWVOfdbWlokjT1MHD+IioFGANxMu7BE/mhqatKWLVsUCATGPFZaWqpgMKhNmzYpGo0qGo3qtddeU0lJidPGPm9qjBlzA4B0TNuwDAaDXpeQV7K1vKqrqyVJbW1t2rRpk7Zv365FixaNW9Nzzz2n7u5ubdiwIWG72AFKADAR0y4s7Q/OlStXelxJfsjm8urt7dWyZcskSZWVlZI0ak8xnr13WVlZqaamJi1ZsmTU442NjZKknTt3KhqNSvrT6FgASEdehOXQ0NCo/8fetz8E7X/j20vH9lLsNjt37lQgEBh1aM/eQ7GDobe313nM3tOx20/0wza2vtj/p9MmlUtHEs0jV5ZXfD+xent7tXTpUl144YWjnj8wMDBqzzB+HvbeZKJDtatXr5Z07Bzl3LlzZVmWFixYoIqKinFrAYAxvBhWlO5oWMVc1pDolqhN7LTYSwUaGxvHjH4Mh8PO4x0dHcYY41xyYF+GYI8KrampcaZNtv5027hdOuK2nLxcXqnWZvcV/3x7dGzs6FdbIBBwLm2JFw6HTU1NjXOpif382D4DgUDSZZoMo2GBaWWzr7/Bxy/fFpMt+bi8otGo7r33XjU0NGS1X77BB5hW8uMbfIBknnjiCVVUVHhdBgCf821Yxp/nxPjyaXnV1taO+lq75cuXe10SAJ/Lm18dSZf96xb2/zN9uCzV7zvNl8N0U728MskeIdvY2KiNGzd6XA2A6cC3YTnVH/a5HCYTkU+vZ+PGjYQkgKzy7WFYAAAyhbAEAMAFYQkAgAvCEgAAF4QlAAAuCEsAAFwQlgAAuCAsAQBwQVgCAOCCsAQAwAVhCQCAC8ISAAAXhCUAAC48+9WRlpYWDQ8Pe9U9MCnt7e1elwAgizwJyzVr1hCUU6y7u1uLFy/W/PnzvS7FlyoqKnTeeed5XQaALLFMPv2QIVJmWZaam5tVVVXldSkAkO+2cM4SAAAXhCUAAC4ISwAAXBCWAAC4ICwBAHBBWAIA4IKwBADABWEJAIALwhIAABeEJQAALghLAABcEJYAALggLAEAcEFYAgDggrAEAMAFYQkAgAvCEgAAF4QlAAAuCEsAAFwQlgAAuCAsAQBwQVgCAOCCsAQAwAVhCQCAC8ISAAAXhCUAAC4ISwAAXBCWAAC4ICwBAHBBWAIA4IKwBADABWEJAIALwhIAABeWMcZ4XQQm5/vf/77uu+8+LVy40Jm2e/duXXDBBTrllFMkSZFIRFdddZW2b9/uVZkAkK+2EJY+UFtbq4cffjiltqxuAEjbFg7D+kBlZaVrm8LCQj344INTXwwA+BBh6QMXXXSRLr744nHbDA8Pa82aNVmqCAD8hbD0iXXr1qmwsDDhY5Zl6ZJLLtEFF1yQ5aoAwB8IS5+orKzUkSNHEj5WUFCgDRs2ZLkiAPAPwtInzjrrLF1++eWaMWPsKh0ZGdGnPvUpD6oCAH8gLH1kw4YNsixr1LQZM2aorKxMp59+ukdVAUD+Iyx95NZbbx0zzbIsrV+/3oNqAMA/CEsfmTdvnq699loVFBQ40yzLShiiAIDUEZY+s379eueLBwoKCnT99dfrpJNO8rgqAMhvhKXP3HTTTc4lJMYYrVu3zuOKACD/EZY+M2fOHK1atUqSNGvWLK1evdrjigAg/82Mn3DkyBF1dHRoZGTEi3qQAeeee67z77PPPutxNZiMJUuW6Mwzz5yy+ff09Gj//v1TNn8gG6Z6O5EkmThPPfWUkcSNG7ccuN15553xm2hGef36uHHLxG2qtxNjzOYxe5aHDh2SJH6dAvDY2rVrdfjw4Snvp7m5WVVVVVPeDzAVsrWdcM4SAAAXhCUAAC4ISwAAXBCWAAC4ICwBAHBBWAIA4IKwBADABWEJAIALwhIAABeEJQAALghLAABcEJYAALggLAEAcEFYAgDgImfDcmhoSG1tbSovL/d0/ona1dbWqra2dkrqmm5Yz/mFZYLpaszvWeaKBx54QDt27PB8/lNdx0REo1G9+uqr+tnPfqZQKKSOjo6E7UKhkJqamiRJGzduVCAQSKsfy7JSajeZ3z5lPSMd0WhUc+fOndB7LpXtZmBgQI888oh27NihYDCoiooKLV++PK1+km03XvxGcPzyyqXa8k78z0E3NzebBJM9oT/+CrbX85/qOtJVU1Njampqxq2rtbXVBAIBE4lETCQSMcFg0DQ2NqbdVyQSSdpPf39/RpYL6zmxqqoqU1VVNaV9SDLNzc1T2kcmdXR0THgduW03kUjEdHR0OP9vbW01kpxp6YjdbiKRyITqzYREy2twcDAnasuUbGwnxpjNhGUefojaktUVDoeNJNPT0+NM6+vrM5JMX19fxvqxH5ss1nNihOVokUjEBAKBSa+jZOs5UShO5j3h9ftpvOXldW2ZlK2wzNg5y6GhIdXX18uyLJWXl6urq8uZHnsuKBQKybIsVVdXa2BgQJLU1tY2ZlqyeafSJrZ/WzQadfopLy/Xvn37Er4Ot3bxryfZ6ysvLx9TZ1dXl8rLy2VZlurr6zU0NOS6XCdiz549kqSFCxc600477TRJ0ksvveRMm8z5J/twjvnj4RvW859kaz1n20SWydDQkEKhkNOmqanJWb+xy9yyLOeWbFpdXZ1CodCoxzIp2WmKYDA46v5Et5t8XF7RaNSpwbIs1dbWjtoG7Vt9fb3znNjHYl9XsnywX280GlV1dXXunhOPj8+J7FkODg6aQCBgWltbjTHGdHZ2Onsx9l82itmr6enpMZJMMBh09n7svaFgMOjM136e3cbuR5IZHBxMqX9bIBAwwWDQOexgH2KJf61u7WJfT/z98V6LfTjEbhM733SXd/zyiRcMBpP+NRkIBJz79mGpdPuxX18s1vMxmVzPubZnOZFlEvva7Tb2aQFJpr+/3xgz+tCgzZ5X7LTJbC/pzsM+lBq/xznR7SaXlleqy8Dud3BwcEytsdt3vEAg4Gy7qeZDT0+P6evrSzi/8eTVYVj7AyGWJOcNlWjFpDItURv7PFns+Te3/u0PMPuNZkzic3GptkulzlTb1NXVmYlKd0OY6AdN7AY83gc/6zmz6znXwtJun4llYp8WiF0uE51XulKdR2dnp3PeP1P95MrySnUZ1NTUJPzD1lZXV2ckmXA4PKpWOxiNST0fJrqc8yosY/86SPSBmsk3TaLpbv2Pt6cVOz3VdhP5wEg078lu+NkOS1uiPctk82c9T3y5+zksMz2vdKQ6j0AgMOq8fyb6yZXlle5yDIfDTjDGPs8O8dg/auvq6kaF50TyIR15FZZuL9aLN00q9WWqv1Rei/2msv/iSvSXYrqS1TveSf10D3Ek68eLsJxu65mw9C4sW1tbJzR63K2fXFle6SzHxsZGEwgEnKM98c+z/0CMHXmfTl/5EpYZ/VKCZIMppkL8Sfds95+u0tJSdXR06MCBA86J8tbWVt19990Z78seqBA7sMQ+0X7ZZZdlpA9jTEbm44b17G+J1q/X9u7dq1deeUUbN270upQxsrW8qqurJR0blLdp0yZt375dixYtGrem5557Tt3d3dqwYUPCdrm83aYiI2HZ2NgoSdq5c6ei0aikP41+yrS9e/dKkpYtW5Zy//bj9nOTSbXdRIRCIV1zzTW6++67ZYxRR0eH1qxZk/F+JOkTn/iEJOlXv/qVM+2NN94Y9VimDAwMTMnoNdazv9kfnCtXrvS4ktGGhob0/PPP66GHHnKm7d271wkPr2RzefX29jrbXWVlpSSppKQkafvS0lIFg0FVVlaqqalJS5YsGfV4NvNhSsXva050NKwSHI8Oh8MJL4CNnRY7Yip+mn04sbOz02kTCATGHNIar39j/nSOLRAIONPsEVmKOTSZSrv4OhO9vtjBIvZrSVRf7DzT5XbRc2NjozPaM9mXEqQyqm+8LyUIh8POSFfWc+bXc64dhp3sMrEPTUciEVNTUzNqZLYxZsyIT3u0Zey6ix0lPZFD2+NtN7GjsONvsSNi091uEm0PXi6vRCNpbfY87BHm9vPD4fCow7Dx72X7eYkOXaeaDxOVV+csjTn2AWR/O0YwGHQ+hOIXUDrTjPnTiDR7vvYHaqr9xz5uv7nsDy57OHPsindrl+zD0O21xA+Tjv8gTcd4fceyR30GAoGEy81to3d7rbEbPus58+s518JyosvE/n/ssmlsbBwTVuFw2HncDqf4dWefA66pqUn7jw+37cZ+PyS6xY6cztR248XySmebTvR8e3Rs/HZn9x27nOJrdcuH+D8GUpWtsLSMGX3yqaWlRWvXrs3aOanpYt++fZo9e/aYwxn79u3TBRdcwPL2iUyu57Vr10qSmpubM1pjLMuy1NzcrKqqqintQxLv8RTl4/KKRqO699571dDQkPW+s7GdSNqSs7864idtbW1atGhRwuP+CxYsUGtrqwdVIdNYz5iunnjiCVVUVHhdxpQiLLOgpaVFTU1NY74Wbd++fXriiScYAOITrOexYkdk++Vr/6ZSPi2v2traUV9rl+6vs+QbwjILdu7cqTlz5uiRRx4Z9R2L+/fvd4anx37P4ng35K5U1vN0s2DBgoT/zxS/bTdTvbwyyT6C0tjYOGr0sF9xzhLIUX45ZwlMJc5ZAgCQIwhLAABcEJYAALggLAEAcEFYAgDggrAEAMAFYQkAgAvCEgAAF4QlAAAuCEsAAFwQlgAAuCAsAQBwQVgCAOBiZrIH2tvbs1kHgDjt7e1Z+UHd9vZ2FRYWTnk/wFTI1nYyJizPO+88SdJtt9025Z0DGN8555wzpfOfNWuWdu3apV27dk1pP8BUmurtRErwe5bwD36rEPDOLbfcosLCQrW1tXldCiaP37P0sxNPPFF/+MMfvC4DmJYOHjyoE0880esykCGEpY8VFRURloBHDh48qOLiYq/LQIYQlj5WVFSk9957z+sygGkpGo2yZ+kjhKWPzZkzh7AEPMJhWH8hLH3shBNO4DAs4BEOw/oLYeljnLMEvHHkyBH9/ve/Z8/SRwhLHysqKlI0GvW6DGDaOXjwoCQRlj5CWPpYcXExe5aAB+yw5DCsfxCWPlZUVKRDhw55XQYw7dhHdNiz9A/C0seKior0+9//3usygGmHw7D+Q1j62AknnKB3333X6zKAaYfDsP5DWPoYl44A3ohGo5o5c6Y+8IEPeF0KMoSw9DEuHQG8wRcS+A9h6WNFRUXO4SAA2RONRjkE6zOEpY8VFxczGhbwAHuW/kNY+lhRUZGGh4d15MgRr0sBphXC0n8ISx8rKiqSJC4fAbKMw7D+Q1j62AknnCBJXD4CZBl7lv5DWPqYHZaMiAWyi18c8R/C0sfsw7CEJZBd/PCz/xCWPmaHJZePANnFnqX/EJY+Zm+sXD4CZBfnLP2HsPQx+6u2OAwLZBeHYf2HsPSxwsJCzZw5k0tHgCw6fPiwDh8+zGFYnyEsfe7444/n0hEgi/h5Ln8iLH1uzpw5HIYFsogffvYnwtLnioqKGOADZBG/ZelPhKXPFRUVcRgWyCIOw/oTYelzJ554IgN8gCziMKw/EZY+94EPfIBzlkAWHTx4ULNnz9Zxxx3ndSnIIMLS5zhnCWQXX0jgT4Slzx1//PF83R2QRXwhgT8Rlj7HpSNAdvG9sP400+sCkFmvv/66hoaGFI1G9X//93/av3+/wuGwGhoadPDgQR06dEgvvviivvGNb+iMM87wulwgr0UiEW3btk1z585VcXGxTjzxRL300ks6fPiwnn/+eWfa3LlztWDBAq/LxSRYxhjjdRHIjLfeekvz588fM72goEAzZszQjBkzdPToUQ0PD2vnzp1at26dB1UC/vGf//mfuuyyyyRJxx13nIwxGhkZ0cjIyJi2e/fu1SWXXJLtEpEZWwhLnznllFP09ttva7zValmW3nzzzYTBCiB1xhjNnz9fv/3tb13bvvPOO5o7d24WqsIU2MI5S5/54he/qIKCgqSPW5alSy+9lKAEMsCyLN14440qLCxM2qawsFB/+Zd/SVDmOcLSZ9avXy/LspI+PnPmTFVUVGSxIsDfVq5cqSNHjiR9fHh4WJs3b85iRZgKhKXPnHzyybrllluS/qU7PDysVatWZbkqwL8+/vGPa8aMxB+lM2bM0GWXXeac10T+Iix9KBgManh4OOFjZ555pj7ykY9kuSLAv4qLi3XFFVckPaLz2c9+NssVYSoQlj50zTXX6Nxzzx0zfdasWbr55ps9qAjwt0AgoJkzx16JN2fOHE57+ARh6UOWZam6unrMxvv+++9r9erVHlUF+NeqVavGHM0pLCzUpk2bVFRU5FFVyCQuHfGp3/72tzrttNNGDTw4/vjj9c4774w7cg/AxJx66qkaHBx07luWpddeey3hUR7kHS4d8atTTjlFn/zkJ51gnDlzplatWkVQAlMkEAiM2t6uv/56gtJHCEsfu+uuu5xDQ0ePHuUQLDCFVq1a5RzJOXLkiLZu3epxRcgkDsP6mDFG5557rn7zm9+ooKBAb731lj74wQ96XRbgS++9957mzp2rkZERnX766RoYGEh6SQnyDodh/cwe6CNJH/3oRwlKYAqdcMIJuvTSSyVJW7duJSh9xnd7lscdd5zef/99r8tAHnnxxRd1+eWXe1oD71sgN8yaNUuHDx+On7zFdz/R9f777+umm25SVVWV16XkjDfffFPz5s0b9ztjp6vbbrtNr732mudhyfvWH44cOaLf/e53/BxXnmppadGuXbsSPua7sJSkiooKLgRG3uF9C3hreHg4aVhyUB0AABeEJQAALghLAABcEJYAALggLAEAcEFYAgDggrAEAMAFYQkAgAvCEgAAF4QlAAAuCEsAAFwQlgAAuCAsAQBwQVgCAOBiWofl0NCQ2traVF5e7nUpgOementIdf6J2tXW1qq2tnZK6ppuWM8T48vfs0zVAw88oB07dqT1nGg0qrlz58oYM0VVJe7z1Vdf1c9+9jOFQiF1dHQkbBcKhdTU1CRJ2rhxowKBQFr9WJaVcPp4r7W3t1ff/va3tWPHDgWDQVVUVOhjH/vYqGWUbL6p6unp0ZIlS5L2v3Tp0pTrRXIT2R6mYv5TXcdEpLINprqdjifVbWUy73HW8wQZn5Fkmpub02qfzmLo6OhIq30m1NTUmJqamnFrbW1tNYFAwEQiEROJREwwGDSNjY1p9zU4OOj0E4lExm3b09NjJJnW1lZnWl9fnwkEAqPqjG9jT4t/La2trc60cDjstAkGg0lrCAaDTrvBwcGUX2dsHem8X6ZKLtUxle/vVOc/1XWkK5VtMJU2qYhEIknn0d/fn5HlwnpOrLm5OVk9m3OnygyZyrCMRCJjgiCbktVqB0tPT48zra+vz0gyfX19Gesnnh1U8ey+Y+eXSh/2h0Rsm7q6OiPJhMPhMfMIh8PO4xNdJ7kUUrlSBx+iyaVSVyZqH28ehOXUGS8sp/U5y2Tq6+tlWZaampo0NDTkHBqpq6tTKBSSdOxwiWVZY467h0IhWZal6upqDQwMSJLa2trGTMukPXv2SJIWLlzoTDvttNMkSS+99JIzLdPnAw4cOCBJ2rt376jppaWlo+6Hw+GU5ldcXDym7YoVKyT96TXG2rNnj/P4dDQ0NOS8V8vLy9XV1eVMn+x7MnbeqbSJ7d8WjUadfsrLy7Vv376Er8OtXfzrSfb6ysvLx9TZ1dWl8vJyWZal+vp6DQ0NuS7XqTSZbdD+HDJ/PATLev6TrKznLAf3lNMk9yzr6uqcvZhIJOIcVknW3t7TVMxenH14MhgMOnt79t7feIcU063VlmwPT5IJBALOffsw0UT7iWfvQUoyjY2Nrodt0+3DfjzZ67OXZar1JusjV/bo0qljcHDQBAIB5/B2Z2en8x6czHvSfp7dxu5HcYe5x+vfFggETDAYdN4X9mH2+HXl1i729cTfH++12KdM7Dax853M+yWV922yNhPdBu3XF4v1fEwm1zOHYV3ax4dh/JtlvLCc7LR0JHt+utMn2k8i/f39o84btra2phSa6YSlvYHGH2bu7OxMu95EfeRjWMae342dh/1BPNH3ZKI29nmy2HPgbv3bH2D9/f3O44nOxaXaLpU6U21TV1dnJmqyYZluP/G3VPpiPU98PROWLu1jF479wZ/sQ5+wTKynp2dUaHZ0dEy6j/gNIvavydi/zqdjWMb+1Z3oAzWTH6KJprv1P97RjkTbm1u7iXyIJpr3VG2Dmewj0TwS7Vkm64v1PPF1QFi6tI9dOP39/aPeIPF/neRiWCYbdBQfMJPtJxU9PT1OPeMFZrphaf+FGw6HzeDg4KjRtdMxLN1e81R/iE6k/0z2l8prsU8T2O8V+34+7VnGT0u1Hes583uWDPCJs2jRInV0dKivr0/BYFDbtm1TfX2912WNy76eMvaktn0C/LLLLst4f9XV1ZKODTiIRqOjHluyZIm2b98uSRm96LmsrEzSsUE9XV1dzv3pLtlgiqkQDAY97T9dpaWl6ujo0IEDB2RZlmpra9Xa2qq7777b69Im5FhOTD3Wc2KEZRw7AEpLS9XQ0KC+vj5t27bN67LG9YlPfEKS9Ktf/cqZ9sYbb4x6LFN6e3u1bNky5/7LL788pk1JSYkkpf2lCOMpKSlRTU2NKisrdeDAAaeP6aqxsVGStHPnTucPFnvUYqbZo51j17tb//bj8SOl46XabiJCoZCuueYa3X333TLGqKOjQ2vWrMl4P9k2MDAwJd9yw3p2kfZ+ao5TGoezYi/Atwf1SMdOXtsjYu1r+WyxI8bq6uoSXsSfaL6JpqUj9mR4onOpjY2NzkizZF9KkMpIvNg649kj7eyRcHa7zs5Op6ZIJOIcMk12jWcqy8JuE/t4omtHJ7tc03m/TKV064h93bE3+zD1RN+T9vvbHjxlj4aMP6Q1Xv/G/OkcWyAQcKbZA7UUc3oglXbxdSZ6fbHbR+y2nOhmzzNdbttgKm1S2QbH+1KCcDjsjHRlPWd+PXPOcpy2sTd7mh2ESnDc2/7ArqmpSfhGGm++8dPSeU2JbvHsEWeBQMDZCGK5bajJ+om/2W9cu4b+/n7T2NjoPF5TUzNq1Fu6r2W8xxMNf5/sss3HsDTm2AeQfWlTMBh0PoQm+57s7Ox0PkyDwWDC99J4/cc+bg++sD+47MsQYj/E3Nq5vR+TvZb4y2jiP0jTMdH3bXybTG6DrOfMr+fxwtL6YwG+YVmWmpubVVVV5XUpyAO58n7JlTr8ZN++fZo9e/aYQ/b79u3TBRdckLVzgJhamVzPLS0tWrt2baLnbOGcJQDfaWtr06JFixKe216wYIFaW1s9qAqZls31PK1/dQSAP7W0tOjdd9/VJz7xiVEfpPv27dO///u/a+PGjR5Wh0zJ5npmz9Ij9nfLut0ApG/nzp2aM2eOHnnkEWdbqq2t1f79+50PULbB/JfKes4U9iw9wvkSYOoUFxdrzZo1WrNmjRoaGhK2YRvMf6ms50xhzxIAABeEJQAALghLAABcEJYAALggLAEAcEFYAgDggrAEAMAFYQkAgAvCEgAAF4QlAAAuCEsAAFwQlgAAuCAsAQBwYRmfffU+P6mDdD311FO66aabPK2B9y2QOxLE4hbf/UTXnj17tH//fq/LmLZeeOEFbd++XbfddptuueUWr8txVVBQoBtvvNHrMnjfToGf//zn+spXvqLzzz9f9957r9flIE+cccYZCaf7bs8S3mtoaNDWrVt1xx13aMeOHZo503d/kyHHPf7447rjjjt0ww036Lvf/a6OP1lV1/oAABd6SURBVP54r0tCftvCOUtkXHV1tXbt2qW2tjYFAgG99957XpeEaeTv/u7vVFlZqWAwqO9973sEJTKCPUtMmf/4j/9QIBDQwoUL9cwzz+i0007zuiT42JEjR/TpT39a3/zmN/Xoo49q69atXpcE/2DPElPnz//8z9XT06NDhw5pyZIleuWVV7wuCT717rvvatWqVWppadGTTz5JUCLjCEtMqXPOOUd79uzRWWedpauvvlo//OEPvS4JPrN//35deeWV+q//+i/96Ec/Unl5udclwYcIS0y5k046Sf/2b/+mFStW6IYbblBLS4vXJcEn+vr6dMUVV+jo0aN68cUX9Wd/9mdelwSfIiyRFbNnz9bjjz+urVu3at26dXrkkUe8Lgl57rnnntPVV1+tCy+8ULt371ZJSYnXJcHHCEtkjWVZqqur0z/90z+ptrZWd911l0ZGRrwuC3mooaFBgUBAt956q5577jkVFxd7XRJ8jrBE1m3ZskXf//739d3vflerV6/m0hKk7OjRo7rnnnu0efNmPfDAA/rWt76lwsJCr8vCNMClI/DMiy++qPLycpWUlCgUCunUU0/1uiTksD/84Q9av369QqGQ/uVf/kVr1671uiRMH1w6Au9cccUV2rNnj6LRqJYuXapXX33V65KQo4aGhnTdddepq6tLP/jBDwhKZB1hCU996EMfUk9PjxYuXKgrr7xS3d3dXpeEHNPf36+ysjINDg5q9+7dWrZsmdclYRoiLOG5k08+WZ2dnVq+fLk+/vGP6/HHH/e6JOSI7u5ulZWVad68eerp6dHixYu9LgnTFGGJnDB79mw98cQTqq6uVmVlpf7hH/7B65LgsZaWFn384x/Xtddeq66uLs2fP9/rkjCNEZbIGTNmzNCjjz6qRx99VPfff782b97MpSXT1MMPP6x169Zpy5YteuKJJ1RUVOR1SZjm+O0k5JzPfvazOvPMM7Vu3Tq9/vrram1t5Zcjponh4WHddddd+s53vqPt27fr05/+tNclAZK4dAQ5rKenR+Xl5Tr33HPV0dGhBQsWeF0SplA0GtWtt96q3t5ePf7441q5cqXXJQE2Lh1B7lq6dKn27Nmjt99+W2VlZerv7/e6JEyRgYEBXXXVVfqf//kfdXd3E5TIOYQlctr555+vPXv2aP78+SorK9Pu3bu9LgkZ9vLLL+uKK66QZVnq7e3VpZde6nVJwBiEJXLevHnz1NXVpWuuuUYrVqxQe3u71yUhQ0KhkJYtW6ZLLrlEP/7xj3XmmWd6XRKQEGGJvFBUVKTvfe972rRpk9asWaP6+nqvS8Ikbd++XTfffLMqKyv1zDPP6MQTT/S6JCApRsMibxQUFOirX/2qzjrrLN1zzz0Kh8N69NFHVVBQ4HVpSMPIyIjuuecePfbYY/rbv/1b3XfffV6XBLgiLJF3vvCFL6ikpES33367Xn/9dbW0tHAdXp44dOiQ1q1bp2effVYtLS1as2aN1yUBKeHSEeSt3bt3q7y8XOeff75CoZDmzZvndUkYx+DgoMrLy/XLX/5Su3bt0lVXXeV1SUCquHQE+evKK69UT0+P3nrrLS1dulS/+MUvvC4JSbz66qtaunSp3n77bfX09BCUyDuEJfLaokWL1NPTo5NPPlllZWXas2eP1yUhzg9/+ENdeeWVOu2009TT06Pzzz/f65KAtBGWyHvz589XV1eXysrKtGLFCj355JNel4Q/+s53vqMbbrhBK1asUGdnp0455RSvSwImhLCELxx//PF68skndeedd6qiokJf/epXvS5pWjPG6Etf+pLuuOMOfe5zn9Pjjz+u2bNne10WMGGMhoVvFBQU6Otf/7rOPvtsff7zn9evf/1r/eM//qNmzOBvwmx6//33tWnTJjU3N2vHjh3atGmT1yUBk0ZYwnfuuecenXXWWVq/fr3279+vnTt3cmlJlrzzzju65ZZb9JOf/EShUEg33HCD1yUBGcGlI/Ct7u5u3XzzzVq8eLGefvppzpdNsV//+te68cYbdfDgQf3rv/6rSktLvS4JyBQuHYF/XXPNNfrxj3+s//3f/1VZWZl++ctfel2Sb7300ksqKyvTrFmz1NPTQ1DCdwhL+NqFF16oPXv2qLi4WEuXLtWLL77odUm+89RTT2n58uW69NJL1d3drTPOOMPrkoCMIyzhe6eeeqp++MMf6vLLL9fy5cu1a9cur0vyjccee0wVFRVat26dOjo6NGfOHK9LAqYEYYlp4YQTTtDTTz+t22+/Xbfeequ+9rWveV1SXhsZGdFnPvMZfeELX9CXv/xl7dixQzNnMl4Q/lXw4IMPPuh1EUA2zJgxQzfeeKNmzZqle+65R++++66uv/56WZbltHnrrbc0b948zZgxQ1dffbWH1XrvpJNO0m9+8xvdeOONo6b//ve/12233ab29na1trZq48aNHlUIZM2zjIbFtNTS0qI777xTq1ev1ne+8x3Nnj1bhw4d0tVXX62f/vSnkqQ33nhDp512mseVeuPpp5/WTTfdJEl65JFHdO+990qS3nzzTd14440Kh8Pq6OjQ0qVLvSwTyJYthCWmrR/96Ef65Cc/qYsvvtj59p8f/OAHOnLkiAoLC7V27Vp961vf8rrMrDt8+LAWL16sgYEBHT16VJZlaefOnfroRz+qlStX6rjjjtNzzz2nD33oQ16XCmQLYYnp7ZVXXtGqVat0xhlnqKenR0ePHnUesyxLL7/8si699FIPK8y++vp6/c3f/I1GRkacaQUFBZo9e7YuvfRSPf300zrppJM8rBDIOsIS+MpXvqK//uu/HjO9sLBQV1xxhV544QUPqvLGW2+9pbPPPluHDh0aNb2goECzZs3ST37yE1100UUeVQd4hi8lwPTW0dHhnI+LNzw8rB//+MfT6lKT+++/X8PDw2Omj4yM6MiRI1q5cqXeeustDyoDvMWeJaatF198UcuWLdP777+vZJvBjBkzVFJSon379qmwsDDLFWZXX1+fPvaxj406FB2vsLBQH/nIR/TCCy/oAx/4QBarAzzFniWmryVLlujw4cNJg1KSjh49qtdff13bt2/PYmXe+MxnPqOCgoJx2wwPD+unP/2p7rzzzixVBeQGwhLT1jPPPKOysjJZljXuXuPIyIgeeOAB/e53v8tiddn15JNP6oUXXkh4CNY2c+ZMFRQUaPny5fp//+//ZbE6wHschsW094tf/EKNjY1qamrSu+++K8uyRo0ElY4dfrzrrrt8+c0/hw8f1vnnn68DBw6MOQRbWFio4eFhnXnmmQoGg7rjjju0cOFCjyoFPMNoWMB2+PBhPfnkk/r617+u3bt3O0FhKygo0H//939r8eLFHlaZeX//93+vL37xi6P+QLC/um716tW66667dN111/Ej2pjOCEsgkZ///Of653/+Z33zm9/Ue++9J+nY+csbbrhBzz33nMfVZc6bb76phQsXyhjj/HFwzjnnqLq6Whs2bND8+fO9LhHIBYQlvHX//ffrtdde87qMpEZGRrR//3699tprevvttyVJf/EXf6F58+Z5XFlmdHd3a3BwUJJUUlKic889N6dfW0FBgR599FGdeuqpXpeC6YWwhLfsLzGvqKjwuBJ3Bw8e1L59+7R48WKdcMIJXpeTEW+++abeeOMNffjDH9asWbO8LsdVe3u7mpubVVVV5XUpmF628Js68BwffkhV7C/EANnEGXsAAFwQlgAAuCAsAQBwQVgCAOCCsAQAwAVhCQCAC8ISAAAXhCUAAC4ISwAAXBCWAAC4ICwBAHBBWAIA4IKwBADABWEJAIALwhJ5Y2hoSG1tbSovL/e6FADTDGGJvPHAAw+osrJSoVAo5edEo9Gs/wZiNBpVb2+vmpqakgZ7Km3cWJaV8Dae3t5eVVdXy7IsVVdXq6ura8wySjbfVG+9vb3j9p9OvUCuICyRNxoaGtJ+Tnd39xRUMr66ujo988wz2rRpU9JgT6WNG2OMBgcHnfuRSETGmKTte3t7tXTpUi1btkzGGDU0NOjkk0/W7bffPqZta2urjDHOLbZP+9ba2upMC4fDTptvf/vbSWuIfWxwcHDceoGcYgAPSTLNzc1ptU/1bRuJREwgEEi5faalUms6r2ey8wgGgwnb9fX1jZqeqE2iPiKRyJjn1dXVGUkmHA6PmUc4HHYen+hrTvf9AmTIZvYskffq6+tlWZaampo0NDTkHNqrq6tz9trsQ37x5z1DoZBzSHJgYECS1NbWNmaaF2pra1VbW5ux+R04cECStHfv3lHTS0tLR92P3UscT3Fx8Zi2K1askCTt2bNnTPs9e/Y4jwN5x+u4xvSmSe5Z1tXVOXsxkUjE1NTUjNnbib1v72lKMn19fcYYY3p6eowkEwwGTU9PjzHm2F6QPW0yr81tExuvTU1NjampqclIP8b8aQ9SkmlsbDSRSMT1Oen0YT+ebA/WXpap1pusD/Ys4YHNhCU8NdmwlGQGBwed+4ODg+OG5WSnpWOyYZnJfmz9/f1OmEkyra2tKYVmOmHZ2dlpJDl/eBhzLKg7OzvTrjdRH4QlPMBhWOS3YDCoBQsWqK2tTdFoVPPnz2fQyDgWLVqkhoYG9fT0KBgMqrKyUnPnzp3wIKNEli9fLmn0YJ7vfe97znQgHxGWyGuf//znFQgEnA/9+vp6r0vKC0uWLHFCMxAIqLy8PKOB2draqh07dmhgYEBDQ0O6+OKLMzZvwAuEJfLaokWL1NHRob6+PgWDQW3bto3AjFNdXS3p2CCnaDQ66rElS5Zo+/btkpTRL3soKyuTdGxQT1dXl3MfyFeEJfKaHQClpaVqaGhQX1+ftm3b5nVZOaO3t1fLli1z7r/88stj2pSUlEiSAoFAxvotKSlRTU2NKisrdeDAAacPIF8RlsgbQ0NDCf9fV1fnXOLxwQ9+UHV1dc5jdgAMDQ2pvr5+1PPsvaxE803WV6pi9+Di9+ZSbZPKpSPj1WZ/CcGFF17oTLvuuuucb+2x+21ra5MkPfTQQ659JOsv0XK79dZbJWnU5SKTXa6AVwhL5I0FCxYk/P/WrVvV3t4uy7LU3t6uu+++23nMDoCvfe1ruv3220c9b+7cuUnnm6yvVFiW5czb7if+a91SaZNKP7G1xX+N3NKlSyVJZ599ttPGGKMzzjhDTzzxhFPDK6+8ov7+/jHXWybqY8GCBQlfS+xysx8vLS1VMBh05pvKvIBcZRmGDsJDlmWpublZVVVVXpeCPMD7BR7Zwp4lAAAuCEsAAFzM9LoAIB+kem6NsxqAPxGWQAoIQWB64zAsAAAuCEsAAFwQlgAAuCAsAQBwQVgCAOCCsAQAwAVhCQCAC8ISAAAXhCUAAC4ISwAAXBCWAAC4ICwBAHBBWAIA4IJfHYHn1q5dq127dnldBgAkRVjCU/fdd59ee+01r8vIOd3d3Vq8eLHmz5/vdSk5Zc2aNVq+fLnXZWAasgw/1AfkHMuy1NzcrKqqKq9LASBt4ZwlAAAuCEsAAFwQlgAAuCAsAQBwQVgCAOCCsAQAwAVhCQCAC8ISAAAXhCUAAC4ISwAAXBCWAAC4ICwBAHBBWAIA4IKwBADABWEJAIALwhIAABeEJQAALghLAABcEJYAALggLAEAcEFYAgDggrAEAMAFYQkAgAvCEgAAF4QlAAAuCEsAAFwQlgAAuCAsAQBwQVgCAOCCsAQAwAVhCQCAC8ISAAAXhCUAAC4sY4zxughgOvv+97+v++67TwsXLnSm7d69WxdccIFOOeUUSVIkEtFVV12l7du3e1UmMJ1tISwBj9XW1urhhx9OqS2bK+CJLRyGBTxWWVnp2qawsFAPPvjg1BcDICHCEvDYRRddpIsvvnjcNsPDw1qzZk2WKgIQj7AEcsC6detUWFiY8DHLsnTJJZfoggsuyHJVAGyEJZADKisrdeTIkYSPFRQUaMOGDVmuCEAswhLIAWeddZYuv/xyzZgxdpMcGRnRpz71KQ+qAmAjLIEcsWHDBlmWNWrajBkzVFZWptNPP92jqgBIhCWQM2699dYx0yzL0vr16z2oBkAswhLIEfPmzdO1116rgoICZ5plWQlDFEB2EZZADlm/fr3zxQMFBQW6/vrrddJJJ3lcFQDCEsghN910k3MJiTFG69at87giABJhCeSUOXPmaNWqVZKkWbNmafXq1R5XBECSZnpdAKa3I0eOqKOjQyMjI16XkjPOPfdc599nn33W42pyy5IlS3TmmWd6XQamIb5IHZ7atWuXbr75Zq/LQJ6488479c1vftPrMjD9bGHPEp46dOiQJH5NA+7Wrl2rw4cPe10GpinOWQIA4IKwBADABWEJAIALwhIAABeEJQAALghLAABcEJYAALggLAEAcEFYAgDggrAEAMAFYQkAgAvCEgAAF4QlAAAuCEsAAFwQlvCFoaEhtbW1qby83OtSAPgQYQlfeOCBB1RZWalQKOR1KRO2d+9eWZbl3Kqrq9N6fuxz42/19fUKhUKKRqNTVD3gb4QlfKGhocHrEibtpZdeGnV/5cqVaT3fGKPBwUHnfiQSkTFGxhitWLFCTU1Nuv322zU0NJSReoHphLAEcsSpp57qhJsxRoFAIO15zJ8/3/l/cXGx8//S0lJ94xvfkCT91V/9FXuYQJoIS+SlaDSqtrY2WZal8vJy7du3L2G7oaEh1dfXO+26urqc6bHnOEOhkNNmYGBg1Dzs5zc1NWloaEiWZaXURzoGBgZUXl6u2tpa9fb2JmxTW1ur2tratOdtmz9/vj73uc8pFAqpu7t71GP5spwAzxjAQ83NzWYib8NAIGCCwaCJRCLGGGNaW1uNpFHzGhwcNIFAwLS2thpjjOns7DSSTF9fnwkEAk77np4eY4wx4XDYSDLBYNCZR11dnQmHw8YYYyKRiKmpqUm5j3R0dHQ49UgygUDADA4OjmpTU1NjampqXOcVvxxiRSKRMa8xX5ZTVVWVqaqqSrk9kEGbCUt4aiJhaQdLf3+/M80Ogdh52QEaS5ITOIlCJX6apFGhNTg4mFYf6YhEIqavr88JmsbGxrTnYfc/3jLN1+VEWMJDmzkMi7zz7LPPSpIWLVrkTIs9P2draWmRNHqUqCQ9/PDDKfcVDAa1YMECtbW1KRqNav78+TLGZLSP2NdQWlqqhx56SI2NjVkb2ZtvywnwhNdxjeltInuWSrLnFD89WbvxHo+f1t/fP+pQZF1dXUq1TJa9pzwR49Vkzzd2jy5flhN7lvAQe5bwv2SDf1KxaNEidXR0qK+vT8FgUNu2bVN9fX1G+0ikuLhYwWAwo/OUpJdfflmSdO211455LB+XE5AthCXyTmNjo6RjF/Gn0m7nzp3OpRL2iMxUWZalaDSq0tJSNTQ0qK+vT9u2bctoH4lEo1FVVFRMah7xhoaG9NhjjykQCGj58uXO9HxeTkDWeL1vi+ltIodh7dGYgUDAGYFpj65UzChNe5BJ/C0cDo96zB5RGztIyB6soj8esrT7CYfDow4xjtdHqlpbW01nZ+eo19fR0TGmXSqjYWNfg/26jDHOyNZEo2zzZTlxGBYe4jAs8k9JSYnC4bBOP/10nXXWWaqurtaHP/xhBQIBtba26ktf+pKkY9cVhsNh1dTUSDo2CCUcDqukpEQLFixw5jd37txR/0oa9fjWrVvV3t4uy7LU3t6uu+++23lsvD5Sdfzxx+u6666TZVmqra3VO++8M6EvJLAsa9RrmDt3rjOY5vnnn9f999+vjo6OUV9c4PYacmk5AV6yjIkZsgZkWUtLi9auXSvehnCzdu1aSVJzc7PHlWAa2sKeJQAALghLAABczPS6AMCv4r8bNRkOQQO5j7AEpgghCPgHh2EBAHBBWAIA4IKwBADABWEJAIALwhIAABeEJQAALghLAABcEJYAALggLAEAcEFYAgDggrAEAMAFYQkAgAvCEgAAF/zqCHJCe3u71yUgx7W3t6uiosLrMjBNEZbw1HnnnSdJuu222zyuBPngnHPO8boETFOW4Uf3AAAYzxbOWQIA4IKwBADABWEJAIALwhIAABf/H4BjQ+ncM8SUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, './plot_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:50:03.888891Z",
     "start_time": "2019-11-20T05:50:03.877899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x1e15472f488>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x1e1f4db1b08>,\n",
       " <tensorflow.python.keras.layers.embeddings.Embedding at 0x1e1f4be4888>,\n",
       " <tensorflow.python.keras.layers.embeddings.Embedding at 0x1e15470e1c8>,\n",
       " <tensorflow.python.keras.layers.recurrent.LSTM at 0x1e15470e548>,\n",
       " <tensorflow.python.keras.layers.recurrent.LSTM at 0x1e154728d88>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1e15471c608>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:47:02.971715Z",
     "start_time": "2019-11-20T05:47:02.758837Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot iterate over a tensor with unknown first dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-d3f9564ecfc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mencoder_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m   \u001b[1;31m# input_1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_h_enc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_c_enc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m   \u001b[1;31m# lstm_1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mencoder_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstate_h_enc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_c_enc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mencoder_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\advpjt\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    554\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m       raise TypeError(\n\u001b[1;32m--> 556\u001b[1;33m           \"Cannot iterate over a tensor with unknown first dimension.\")\n\u001b[0m\u001b[0;32m    557\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m       \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot iterate over a tensor with unknown first dimension."
     ]
    }
   ],
   "source": [
    "encoder_inputs = model.input[0]   # input_1\n",
    "encoder_embedding = model.layers[2]\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[4].output   # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]   # input_2\n",
    "decoder_embedding = model.layers[3]\n",
    "decoder_state_input_h = Input(shape=(latent_dim,), name='input_3')\n",
    "decoder_state_input_c = Input(shape=(latent_dim,), name='input_4')\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[5]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:46:09.422824Z",
     "start_time": "2019-11-20T05:46:08.633274Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape (None, None) must have rank at least 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-6ab4842dd6e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mdecoder_states_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdecoder_state_input_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_state_input_c\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m decoder_outputs, state_h, state_c = decoder_lstm(\n\u001b[1;32m---> 16\u001b[1;33m     decoder_input, initial_state=decoder_states_inputs)\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mdecoder_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstate_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_c\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mdecoder_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\advpjt\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    660\u001b[0m       \u001b[1;31m# Perform the call with temporarily replaced input_spec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_input_spec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m       \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    663\u001b[0m       \u001b[1;31m# Remove the additional_specs from input spec and keep the rest. It is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m       \u001b[1;31m# important to keep since the input spec was populated by build(), and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\advpjt\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    840\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[0;32m    841\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m                     \u001b[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m                     \u001b[1;31m# circular dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\advpjt\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m    965\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m         (last_output, outputs, new_h, new_c,\n\u001b[1;32m--> 967\u001b[1;33m          runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n\u001b[0m\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m       \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\advpjt\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mlstm_with_backend_selection\u001b[1;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, activation, recurrent_activation)\u001b[0m\n\u001b[0;32m   1286\u001b[0m   \u001b[1;31m# grappler will kick in during session execution to optimize the graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m   last_output, outputs, new_h, new_c, runtime = defun_standard_lstm(\n\u001b[1;32m-> 1288\u001b[1;33m       **params)\n\u001b[0m\u001b[0;32m   1289\u001b[0m   \u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefun_cudnn_lstm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\advpjt\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1820\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1822\u001b[1;33m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1823\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\advpjt\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2150\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\advpjt\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2041\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2043\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\advpjt\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    913\u001b[0m                                           converted_func)\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\advpjt\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mstandard_lstm\u001b[1;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, activation, recurrent_activation, mask, time_major, go_backwards)\u001b[0m\n\u001b[0;32m   1092\u001b[0m       \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1093\u001b[0m       \u001b[0mgo_backwards\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgo_backwards\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1094\u001b[1;33m       input_length=timesteps)\n\u001b[0m\u001b[0;32m   1095\u001b[0m   return (last_output, outputs, new_states[0], new_states[1],\n\u001b[0;32m   1096\u001b[0m           _runtime(_RUNTIME_CPU))\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\advpjt\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mrnn\u001b[1;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[0;32m   3902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3903\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0minput_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflatted_inputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3904\u001b[1;33m     \u001b[0minput_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_rank_at_least\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3905\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3906\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\advpjt\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36mwith_rank_at_least\u001b[1;34m(self, rank)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \"\"\"\n\u001b[0;32m   1031\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shape %s must have rank at least %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape (None, None) must have rank at least 3"
     ]
    }
   ],
   "source": [
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_input, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_input, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_input] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-13T07:51:55.382Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Reverse-lookup token index to decode sequences back to\n",
    "# # something readable.\n",
    "# reverse_input_char_index = dict(\n",
    "#     (i, char) for char, i in input_token_index.items())\n",
    "# reverse_target_char_index = dict(\n",
    "#     (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(10):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
